---
title: "main.Rmd"
author: "Fernando Alvarado"
date: "2025-05-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

#Ruta de los datos en caso de que requiera

#Cargamos nuestras librerías 
library(ggplot2)
library(dplyr)

library(esquisse)
library(tidymodels)
library(tidyverse)
library(skimr)
library(DataExplorer)
library(ggpubr)
library(univariateML)
library(GGally)
library(doParallel)
library(yardstick)
library(knitr)


library(stats )
# Orden de las grafica 
library(patchwork)
```


## Análisis de la presencia de enfermedad

Se proporcionaron datos de un estudio médico realizado a varios pacientes, quienes presentan distintas condiciones clínicas y resultados de estudios complementarios. Entre las variables disponibles, se incluye una variable dicotómica denominada `Y`, que indica si el paciente presenta o no una determinada enfermedad.

Para este análisis, se interpreta de la siguiente manera:

- `Y = 1`: Presencia de la enfermedad  
- `Y = 0`: Ausencia de la enfermedad

Las variables `V1`, `V2`, `V3` y `V4` son **categóricas**, mientras que las variables `V5` a `V10` son **numéricas continuas**. El objetivo principal es explorar la relación entre estas variables y la presencia de la enfermedad, con el fin de identificar posibles patrones o asociaciones relevantes para el diagnóstico o tratamiento.


```{r Data}

data <- read.csv("C:/Users/ferna/Documents/Seminario_Estadistica/Proyecto_3/Ejercicio_2/Data/DatosTrain_Tarea3.csv")
kable(head(data, 5), caption = "Visualizacion de los datos")
```

A partir de estos datos, realizaremos manualmente las interacciones entre todas las variables y llevaremos a cabo una selección de variables utilizando los métodos Stepwise Backward y Stepwise Forward, con el objetivo de encontrar un buen modelo de aprendizaje automático que nos ayude a predecir la presencia de la enfermedad.

```{r Funciones}
# Df, para guarda los datos de los modelos que hemos generado, para poder hacer comparaciones o graficas
df_resultados <- data.frame(
  Titulo = character(), # Variable para describir que modelo estamos usando para trabajar y si usa un metodo de seleccion
  Accuracy = numeric(), # Metrica accuracy, para ver que tan bien esta funcionando el modelo
  TCC_clase_0 = numeric(), # Metrica para evaluar falsos o verdaderos positivos
  TCC_clase_1 = numeric(), # Metrica para evaluar falsos o verdaderos negativos
  stringsAsFactors = FALSE
)




# Agrega una nueva file a nuestro df, Resultados
nueva_fila_resultados <- function(titulo, accuracy, tcc0, tcc1) {
  fila <- data.frame(
    Titulo = titulo,
    Accuracy = accuracy,
    TCC_clase_0 = tcc0,
    TCC_clase_1 = tcc1,
    stringsAsFactors = FALSE
  )
  
  df_resultados <- rbind(df_resultados, fila)
  return(df_resultados)
  
}



#Automatiza la lectura de salida de nuestro modelos de ML, solo debes usar Tydymodels, pasarle el grid y el workflow
# Parametros:
# grid: El grid de hiperparámetros ajustados por el modelo
# workflow: El workflow que contiene el modelo y la receta de preprocesamiento
# trainingDat: El conjunto de datos de entrenamiento (por defecto es train_data)

salidaModelos <- function(grid, workflow, trainingDat =train_data, testing_data = test_data ){
  mejores_hiperpar <- select_best(grid, metric = "accuracy") #grid_fit

modelo_glm <- finalize_workflow(
                x = workflow, #workflow_modelado
                parameters = mejores_hiperpar
              )

modelo_glm_fit <-  modelo_glm %>%
                   fit(
                     data = trainingDat
                   )

#Predicciones 
#=====================================
predicciones <- modelo_glm_fit %>%
  predict(
    new_data = testing_data,
    type = "class"  #Especifico que estoy trabajando con una regresion 
  ) %>% bind_cols(testing_data %>% select(Y))


# MÉTRICAS Accuracy
# ====================================
accuracy_general <- predicciones %>%
  accuracy(truth = Y, estimate = .pred_class)

# TCC clase 1 (Sensibilidad clase 1)
tcc_clase_1 <- predicciones %>%
  sens(truth = Y, estimate = .pred_class, event_level = "second")

# TCC clase 0 (Sensibilidad clase 0)
tcc_clase_0 <- predicciones %>%
  sens(truth = Y, estimate = .pred_class, event_level = "first")

# Guardando los resultados en un data frame, que es lo que vamos a guardar en el df_Final 
out <- list(
  accuracy = accuracy_general$.estimate,
  tcc_clase_0 = tcc_clase_0$.estimate,
  tcc_clase_1 = tcc_clase_1$.estimate
)


return(out)
}


#Funcion para hacer seleccion de variable, usando el metodo Stepwise Backward
#Parametros:
# modelo: Un string con el modelo que se va a usar, por ejemplo "V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10"
# link: El link que se va a usar, por defecto es "logit"
#data: El dataframe que contiene las variables y la variable de respuesta `Y`

StepwiseBack <- function(modelo, link = "logit",  datos){
  
   formula <- as.formula(paste("Y ~ ", modelo ))
  
   model <- glm(formula, family = binomial(link = link), data = datos)
   
   #print( summary(model))
   #Haciendolo Backward
   modelo_step <- stats::step(
      object = model,
      direction = "backward",
      scope = list(upper = model, lower = ~1),
      trace = FALSE
  )
    
  return(modelo_step) 
}





```


```{r Pre_procesamiento}

# Pasando a factores todos los datos

data <- data %>%
  mutate(
    V1 = as.factor(V1),
    V2 = as.factor(V2),
    V3 = as.factor(V3),
    V4 = as.factor(V4), 
    Y = as.factor(Y)
  )
filtro <- data %>% select(-Y)

interacciones_df <- model.matrix(~ .^2, data = filtro)[, -1] %>%  # ^2 = hasta interacciones de orden 2
  as.data.frame()


interacciones_df <- cbind(interacciones_df, Y = data$Y)  # Agregando la variable Y al dataframe de interacciones
colnames(interacciones_df) <- gsub(":", "_x_", colnames(interacciones_df))


```


```{r graficas_categoricas}
V1 <- ggplot(data) +
  aes(x = V1, fill = factor(Y)) +
  geom_bar(position = "fill") +
  scale_fill_manual(
    values = c(`0` = "#095F7E", `1` = "#AF261D")
  ) +
  labs(
    x = "Presencia de enfermedad",
    y = "Proporción",
    title = "Proporción de Y según Variable V1"
  ) +
  theme_minimal()

V2 <- ggplot(data) +
  aes(x = V2, fill = factor(Y)) +
  geom_bar(position = "fill") +
  scale_fill_manual(
    values = c(`0` = "#095F7E", `1` = "#AF261D")
  ) +
  labs(
    x = "Presencia de enfermedad",
    y = "Proporción",
    title = "Proporción de Y según Variable V2"
  ) +
  theme_minimal()

V3 <- ggplot(data) +
  aes(x = V3, fill = factor(Y)) +
  geom_bar(position = "fill") +
  scale_fill_manual(
    values = c(`0` = "#095F7E", `1` = "#AF261D")
  ) +
  labs(
    x = "Presencia de enfermedad",
    y = "Proporción",
    title = "Proporción de Y según Variable V3"
  ) +
  theme_minimal()

V4 <- ggplot(data) +
  aes(x = V4, fill = factor(Y)) +
  geom_bar(position = "fill") +
  scale_fill_manual(
    values = c(`0` = "#095F7E", `1` = "#AF261D")
  ) +
  labs(
    x = "Presencia de enfermedad",
    y = "Proporción",
    title = "Proporción de Y según Variable V4"
  ) +
  theme_minimal()


```

## Análisis de variables categóricas

```{r}
V1 + V2 + V3 + V4 
```

Observando las proporciones de las variables categóricas, se puede notar que ninguna de ellas parece aportar información clara o relevante que explique la presencia de la enfermedad. Por ejemplo, en la variable **V1**, las categorías 0 y 1 presentan proporciones similares tanto en pacientes enfermos como sanos, lo que sugiere que esta variable no discrimina entre los dos grupos.

Este mismo patrón se repite en las variables **V2**, **V3** y **V4**, donde no se observan diferencias significativas en las proporciones de la variable `Y` dentro de cada categoría. Por lo tanto, **estas variables no muestran una asociación visual evidente con la enfermedad**, al menos desde este enfoque descriptivo.


```{r graficas_continuas}

V5 <- ggplot(data) +
  aes(x = factor(Y), y = V5, fill = factor(Y)) +
  geom_violin(trim = FALSE, color = NA, alpha = 0.7) +
  geom_boxplot(width = 0.1, color = "black", outlier.shape = NA) +  # oculta outliers
  scale_fill_manual(values = c(`0` = "#0696C3", `1` = "#DD0D0D")) +
 labs(x = "Presencia de enfermedad", y = "Valor de la variable V5", title = "Distribución de V5 ")
  theme_minimal()
  
V6 <- ggplot(data) +
  aes(x = factor(Y), y = V6, fill = factor(Y)) +
  geom_violin(trim = FALSE, color = NA, alpha = 0.7) +
  geom_boxplot(width = 0.1, color = "black", outlier.shape = NA) +
 scale_fill_manual(values = c(`0` = "#0696C3", `1` = "#DD0D0D")) +
  labs(x = "Presencia de enfermedad", y = "Valor de la variable V6", title = "Distribución de V6") +
  theme_minimal()

V7 <- ggplot(data) +
  aes(x = factor(Y), y = V7, fill = factor(Y)) +
  geom_violin(trim = FALSE, color = NA, alpha = 0.7) +
  geom_boxplot(width = 0.1, color = "black", outlier.shape = NA) +
  scale_fill_manual(values = c(`0` = "#0696C3", `1` = "#DD0D0D")) +
  labs(x = "Presencia de enfermedad", y = "Valor de la variable V7", title = "Distribución de V7") +
  theme_minimal()

V8 <- ggplot(data) +
  aes(x = factor(Y), y = V8, fill = factor(Y)) +
  geom_violin(trim = FALSE, color = NA, alpha = 0.7) +
  geom_boxplot(width = 0.1, color = "black", outlier.shape = NA) +
 scale_fill_manual(values = c(`0` = "#0696C3", `1` = "#DD0D0D")) +
  labs(x = "Presencia de enfermedad", y = "Valor de la variable V8", title = "Distribución de V8") +
  theme_minimal()

V9 <- ggplot(data) +
  aes(x = factor(Y), y = V9, fill = factor(Y)) +
  geom_violin(trim = FALSE, color = NA, alpha = 0.7) +
  geom_boxplot(width = 0.1, color = "black", outlier.shape = NA) +
 scale_fill_manual(values = c(`0` = "#0696C3", `1` = "#DD0D0D")) +
  labs(x = "Presencia de enfermedad", y = "Valor de la variable V9", title = "Distribución de V9") +
  theme_minimal()

V10 <- ggplot(data) +
  aes(x = factor(Y), y = V10, fill = factor(Y)) +
  geom_violin(trim = FALSE, color = NA, alpha = 0.7) +
  geom_boxplot(width = 0.1, color = "black", outlier.shape = NA) +
  scale_fill_manual(values = c(`0` = "#0696C3", `1` = "#DD0D0D")) +
  labs(x = "Presencia de enfermedad", y = "Valor de la variable V10", title = "Distribución de V10") +
  theme_minimal()


```


## Análisis de variables continuas

```{r}
V5 + V6 + V7 + V8 + V9 + V10
```

En el caso de las variables continuas, se observa un cambio relevante en sus distribuciones, ya que la presencia o ausencia de la enfermedad parece influir en la forma de los datos. Por ejemplo, en las variables **V5**, **V6** y **V9**, la enfermedad se asocia con colas más pesadas, lo cual desplaza la media y modifica la simetría de la distribución.

Asimismo, en la variable **V8** se aprecia que los percentiles tienden a agruparse más cerca de la media en los pacientes con enfermedad, lo que sugiere una menor dispersión en ese grupo.

Estos patrones sugieren que la enfermedad tiene un impacto observable en la distribución de las variables continuas, lo cual podría ser útil para desarrollar un modelo de aprendizaje automático (Machine Learning) que permita predecir si un paciente tiene o no la enfermedad. En consecuencia, **las variables continuas parecen ser más informativas** desde un enfoque descriptivo y podrían tener mayor peso explicativo en un modelo predictivo.




```{r Division_datos}

#Dividiendo los datos en training y test
set.seed(12673)  #Poniendo un seed para la reproducibilidad
split <- initial_split(data, prop = 0.8, strata = Y) # Haciendo la division de los datos en training y test
train_data <- training(split)
test_data  <- testing(split)

```


```{r Tools}
#Cosas generales de los modelos 

# Folds de validación cruzada
cv_folds <- vfold_cv(train_data, v = 5, strata = Y) #strata = Y, para asegurar que la variable de estratificación sea Y


# Malla para los hiperparametros, para tunear al modelo
my_grid <- tibble(
  penalty = 10^seq(-3, 2, length.out = 50)
)

#Funcion para outomatizar el preprocesamiento de los datos 
trans <- function(training_data){
  rep <-  recipe(Y ~ ., data = training_data) %>%
        step_nzv(all_predictors()) %>%
        step_center(all_numeric_predictors()) %>%
         step_scale(all_numeric_predictors()) %>%
         step_dummy(all_nominal_predictors())
  return(rep)
}
```





```{r, Modelo_con_todasLasVaribles}
#=============================================================================== Inciso ii) ===============================================================================
# Modelo logit, efectos principales
modelo_glm <- logistic_reg(
  mode = "classification",
  penalty = tune(),
  mixture = 1  # Usando Lasso (mixture = 1 para Lasso, 0 para Ridge, entre 0 y 1 para Elastic Net
) %>%
  set_engine("glmnet")

#modelo_glm%>%translate() # Viendo lo que el modelo esta procesando 

# Receta
transformer <- trans(train_data)

# Workflow
workflow_modelado <- workflow() %>%
  add_recipe(transformer) %>%
  add_model(modelo_glm)

# Tuning
registerDoParallel(cores = parallel::detectCores() - 2) #Funcion para paralelizar el proceso de tuning deje libre 2 cores de tu cpu

grid_fit <- tune_grid(
  object    = workflow_modelado,
  resamples = cv_folds,
  metrics   = metric_set(accuracy, sens, yardstick::spec),
  control   = control_resamples(save_pred = TRUE),
  grid      = my_grid
)

stopImplicitCluster()



```

```{r Resultados_Modelo_Eectos_Principales}}

modeloLogit<- salidaModelos(grid_fit, workflow_modelado)
df_resultados <-nueva_fila_resultados ("Modelo Logit, efectos principales", modeloLogit$accuracy, modeloLogit$tcc_clase_0, modeloLogit$tcc_clase_1)


```

```{r, Modelo_Interacciones}
# Receta, para modelo logit, con efectos principales e interacciones 


transformer_int <- trans(train_data) %>%
 step_interact(terms = ~ all_predictors():all_predictors())
  
# Workflow
workflow_modelado2 <- workflow() %>%
  add_recipe(transformer_int) %>%
  add_model(modelo_glm)

# Tuning
registerDoParallel(cores = parallel::detectCores() - 2)

grid_fit2 <- tune_grid(
  object    = workflow_modelado2,
  resamples = cv_folds,
  metrics   = metric_set(accuracy, sens, yardstick::spec),
  control   = control_resamples(save_pred = TRUE),
  grid      = my_grid
)

stopImplicitCluster()
```

```{r}
modeloLogitInteracciones<- salidaModelos(grid_fit2, workflow_modelado2)
df_resultados <-nueva_fila_resultados ("Modelo Logit, E-P e Interacciones", modeloLogitInteracciones$accuracy, modeloLogitInteracciones$tcc_clase_0, modeloLogitInteracciones$tcc_clase_1)
```

```{r PCA}
library(factoextra)
library(patchwork)
dataNumericas <- data %>% select(V5:V10) # Seleccionando las variables numericas

pca <- prcomp(dataNumericas, scale. = TRUE)


#summary(pca) Resumen del PCA

# Gráficas individuales
g1 <- fviz_contrib(pca, choice = "var", axes = 1) + ggtitle("Contribucion al componente 1")
g2 <- fviz_contrib(pca, choice = "var", axes = 2) + ggtitle("Contribucion al componente 2")

# Lado a lado
#g1 + g2  Graficas para ver que varibales aportan mas a cada componente



```

### Selección de variables

Para la parte de selección de variables en este documento, se realizaron métodos como el Stepwise Backward (`Chunk StepwiseBack`) y un análisis de PCA (`Chunk PCA`). Esto se debió a que, en el caso de variables de solo efectos principales, el método Stepwise (tanto Backward, Forward como Both) solo seleccionaba a la variable `V2` como la única variable que aportaba información al modelo. Por lo tanto, se hizo un **PCA** para identificar cuáles eran las variables que aportaban más información a los dos primeros componentes, que son los que explican mayor varianza. Las variables seleccionadas para efectos principales fueron: `V2`, `V5` y `V8`.

Por otro lado, las variables seleccionadas para el modelo con interacciones fueron: `V5`, `V6`, `V7`, `V10`, `V11_x_V21`, `V11_x_V41`, `V21_x_V41`, `V21_x_V5`, `V21_x_V6`, `V21_x_V7`, `V31_x_V7`, `V31_x_V8`, `V41_x_V5`, `V41_x_V8`, `V41_x_V10`, `V5_x_V6`, `V6_x_V8`, `V7_x_V8`, `V8_x_V9` y `V9_x_V10`. En este caso, las variables de tipo `Vi_x_Vj` representan interacciones entre variables (nombre genérico asignado por R al generar las interacciones en los datos). En este modelo, solo se empleó `Stepwise Backward`.

Los resultados de la seleccion de variables se pueden ver en el chunk `Resultados_Seleccion`

```{r StepwiseBack}
#=============================================================================== Inciso iii) ===============================================================================

Seleccion_EP <- StepwiseBack(".", link = "logit", data)
Seleccio_Interacciones <- StepwiseBack(".", link = "logit",   interacciones_df) # Seleccion de variables usando el metodo Stepwise Backward, de las interacciones


```


```{r Resultados_Seleccion}

#Seleccio_Interacciones
#Seleccion_EP
```


```{r Seleecion_y_split}
df_Seleccion_Interacciones <- interacciones_df %>% select(
  V5, V6, V7, V10, V11_x_V21,  V11_x_V41, V21_x_V41,V21_x_V5 , V21_x_V6 , V21_x_V7 ,V31_x_V7, V31_x_V8 , V41_x_V5 , V41_x_V8, V41_x_V10, V5_x_V6 , V6_x_V8 , V7_x_V8 , V8_x_V9 , V9_x_V10, Y )



df_Seleccion_EP <- data %>% select( V2, Y, V5, V8)


#Division para los datos con interacciones 
split_interacciones <- initial_split(df_Seleccion_Interacciones, prop = 0.8, strata = Y) # Haciendo la division de los datos en training y test
train_data_interacciones <- training(split_interacciones)
test_data_interacciones  <- testing(split_interacciones)

# Division datos Efectos Principales seleccionados
split_EP <- initial_split(df_Seleccion_EP, prop = 0.8, strata = Y) # Haciendo la division de los datos en training y test
train_data_EP <- training(split_EP)
test_data_EP  <- testing(split_EP)

```



```{r Seleccion_EP}
#Modelo con interacciones
# DEFINICIÓN DEL MODELO Y DE LOS HIPERPARÁMETROS A OPTIMIZAR
# =============================================================================
modelo_glm <- logistic_reg(
                 mode    = "classification",
                 penalty = tune(),
                 mixture = tune()
              ) %>%
              set_engine("glmnet")


# DEFINICIÓN DEL PREPROCESADO
# =============================================================================
transformer <- recipe(
                  formula = Y ~ .,
                  data =  train_data_EP
               ) %>%
               step_naomit(all_predictors()) %>%
               step_nzv(all_predictors()) %>%
               step_center(all_numeric(), -all_outcomes()) %>%
               step_scale(all_numeric(), -all_outcomes()) %>%
               step_dummy(all_nominal(), -all_outcomes())

# DEFINICIÓN DE LA ESTRATEGIA DE VALIDACIÓN Y CREACIÓN DE PARTICIONES
# =============================================================================
set.seed(1234)
cv_folds <- vfold_cv(
              data    = train_data_EP,
              v       = 5,
              strata  = Y
             )

# WORKFLOW
# =============================================================================
workflow_modeladoSEP <- workflow() %>%
                     add_recipe(transformer) %>%
                     add_model(modelo_glm)


my_grid <- expand.grid(
  penalty = 10^seq(-4, 1, length.out = 5),
  mixture = seq(0, 1, length.out = 5)
)

# EJECUCIÓN DE LA OPTIMIZACIÓN DE HIPERPARÁMETROS
# =============================================================================
registerDoParallel(cores = parallel::detectCores() - 2)
grid_fitSEP <- tune_grid(
              object    = workflow_modeladoSEP,
              resamples = cv_folds,
              metrics   = metric_set(accuracy, sens, yardstick::spec),
              control   = control_resamples(save_pred = TRUE),
              # Hiperparámetros
              grid      = my_grid
            )
stopImplicitCluster()
```

```{r}
modeloLogitSelectSEP<- salidaModelos(grid_fitSEP, workflow_modeladoSEP, trainingDat = train_data_EP, testing_data = test_data_EP)
df_resultados <-nueva_fila_resultados ("Modelo Seleccion EP", modeloLogitSelectSEP$accuracy, modeloLogitSelectSEP$tcc_clase_0, modeloLogitSelectSEP$tcc_clase_1)
```

```{r Seleccion_Interacciones}
#Modelo con interacciones


# DEFINICIÓN DEL MODELO Y DE LOS HIPERPARÁMETROS A OPTIMIZAR
# =============================================================================
modelo_glm <- logistic_reg(
                 mode    = "classification",
                 penalty = tune(),
                 mixture = tune()
              ) %>%
              set_engine("glmnet")


# DEFINICIÓN DEL PREPROCESADO
# =============================================================================
transformer <- recipe(
                  formula = Y ~ .,
                  data =  train_data_interacciones
               ) %>%
               step_naomit(all_predictors()) %>%
               step_nzv(all_predictors()) %>%
               step_center(all_numeric(), -all_outcomes()) %>%
               step_scale(all_numeric(), -all_outcomes()) %>%
               step_dummy(all_nominal(), -all_outcomes())

# DEFINICIÓN DE LA ESTRATEGIA DE VALIDACIÓN Y CREACIÓN DE PARTICIONES
# =============================================================================
set.seed(1234)
cv_folds <- vfold_cv(
              data    = train_data_interacciones,
              v       = 5,
              strata  = Y
             )

# WORKFLOW
# =============================================================================
workflow_modeladoSI <- workflow() %>%
                     add_recipe(transformer) %>%
                     add_model(modelo_glm)


my_grid <- expand.grid(
  penalty = 10^seq(-4, 1, length.out = 5),
  mixture = seq(0, 1, length.out = 5)
)

# EJECUCIÓN DE LA OPTIMIZACIÓN DE HIPERPARÁMETROS
# =============================================================================
registerDoParallel(cores = parallel::detectCores() - 2)
grid_fitSI <- tune_grid(
              object    = workflow_modeladoSI,
              resamples = cv_folds,
              metrics   = metric_set(accuracy, sens, yardstick::spec),
              control   = control_resamples(save_pred = TRUE),
              # Hiperparámetros
              grid      = my_grid
            )
stopImplicitCluster()
```

```{r}
modeloLogitInteraccionesSI <- salidaModelos(grid_fitSI, workflow_modeladoSI, trainingDat = train_data_interacciones, testing_data = test_data_interacciones)
df_resultados <-nueva_fila_resultados ("Modelo Seleccion e Interacciones", modeloLogitInteraccionesSI$accuracy, modeloLogitInteraccionesSI$tcc_clase_0, modeloLogitInteraccionesSI$tcc_clase_1)
```



```{r, Modelo_Interacciones}
#============================================== Inciso iv) ==============================================
# Modelo Probit
modelo_probit <- logistic_reg(mode = "classification") %>%
  set_engine("glm", family = binomial(link = "probit"))

# DEFINICIÓN DEL PREPROCESADO
# =============================================================================
transformer <- recipe(
                  formula = Y ~ .,
                  data =  train_data_interacciones
               ) %>%
               step_naomit(all_predictors()) %>%
               step_nzv(all_predictors()) %>%
               step_center(all_numeric(), -all_outcomes()) %>%
               step_scale(all_numeric(), -all_outcomes()) %>%
               step_dummy(all_nominal(), -all_outcomes())

# DEFINICIÓN DE LA ESTRATEGIA DE VALIDACIÓN Y CREACIÓN DE PARTICIONES
# =============================================================================
set.seed(1234)
cv_folds <- vfold_cv(
              data    = train_data_interacciones,
              v       = 5,
              strata  = Y
             )

# WORKFLOW
# =============================================================================
workflow_modeladoProbit <- workflow() %>%
                     add_recipe(transformer) %>%
                     add_model(modelo_probit)


my_grid <- expand.grid(
  penalty = 10^seq(-4, 1, length.out = 5),
  mixture = seq(0, 1, length.out = 5)
)

# EJECUCIÓN DE LA OPTIMIZACIÓN DE HIPERPARÁMETROS
# =============================================================================
registerDoParallel(cores = parallel::detectCores() - 2)
grid_fitProbit <- tune_grid(
              object    = workflow_modeladoProbit,
              resamples = cv_folds,
              metrics   = metric_set(accuracy, sens, yardstick::spec),
              control   = control_resamples(save_pred = TRUE),
              # Hiperparámetros
              grid      = my_grid
            )
stopImplicitCluster()



```

```{r}

modeloProbitIN<- salidaModelos(grid_fitProbit, workflow_modeladoProbit, trainingDat = train_data_interacciones, testing_data = test_data_interacciones)
df_resultados <-nueva_fila_resultados ("Modelo Probit", modeloProbitIN$accuracy, modeloProbitIN$tcc_clase_0, modeloProbitIN$tcc_clase_1)

```





```{r}
print(df_resultados)
```

