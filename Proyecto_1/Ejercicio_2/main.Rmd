---
author: "Fernando Alvarado"
date: "2025-03-12"
output: html_document
---


```{r setup, include=FALSE}
#Empezamos limpiando nuestro ambiente
rm(list = ls(all.names = TRUE))


# Configuración global de los bloques de código (chunk's)
knitr::opts_chunk$set(
	echo = FALSE,
	fig.align = "center",
	fig.dim = c(5.0, 4.0),
	fig.pos = "H",
#Agregamos configuraciones para evitar mensajes de advertencias y de errores en el archivo
	message = FALSE,
	warning = FALSE,
	error = F
)



library(dplyr)      # Para el manejo de datos
library(tidyr)

library(ggplot2)    # Para realizar gráficas
library(kableExtra) # Para un mejor manejo de tablas
library(knitr)
library(purrr)      # Para la función map y map2


# Para purebas de hipotesis





#Extrayendo nuestra datas
setwd("C:/Users/ferna/Documents/Seminario_Estadistica/Proyecto_1/Ejercicio_1")

data <- read.csv("./Data/Preg1A.csv")




```


# Exploracion de modelos

En este proyecto se ralizo un algoritmo para encontrar el mejor modelo que modele nuestros datos, se uso regresion multiple, regresion ponderada y modelos generales lineales (normal, gamma, inversa gaussiana), donde cada variable estaba elevada a una potencia. Posterirormente cada modelo fue evaluado usando la metrica AIC y se ordeno de de menor a mayor AIC, para ver cual era el de minimo AIC y evaluar si pasaba los supuestos.


La base de datos que se manejo en este proyecto contiene información sobre 438 pacientes seleccionados de forma aleatoria, donde con nuestro modelo seleccionado  queremos analizar si existe una asociacion entre la presión arterial sistólica (bpsystol) y el índice de masa corporal (bmi), en particular, si es posible observar que tener un índice de masa corporal alto se asocia con una alta presión arterial sistólica.





```{r}
#------------------------------------------------------------------------------------------------------------------------------------------
#Hiperparámetros de nuestro algoritmo 



#Primeros parametros de nuestro algoritmo de la malla 

long_Modelo <- 2 #Longitud que tengra nuestro modelo 
limiteInfMalla <- 0 #Lo que la malla debe de empezar a checar
limSuperiorMalla <- 5 #Limite superior malla
finura <- .3 #Para empezar a hacer pruebas 


#Primeros GLMS

(Distribuciones=c("gaussian", "Gamma", "inverse.gaussian" ))
(FunLigas=c("identity", "log", "inverse", "1/mu^2"))


```


```{r Algoritmo_Malla}
#------------------------------------------------------------------------------------------------------------------------------------------
#Algoritmo malla (Aqui hare la malla para poder elevar a las variables a la potencia que se requiera)



mallaAl <- function(n, liminf, limsup, finura, des_Ponderada = 0 , limInfpon = 0, limSuppon = 2, distribucion  = c(), funcion_liga= c(), numPesos){
  #Parametros
  #n: número de parametros que tiene nuestro modelo 
  #liminf: límite inferior de la malla, para las variables x
  #limsup: límite superior de la malla, para las variables x
  #finura: finura de la malla que deseamos
  #des_Ponderada: si se requiere usar regresion ponderada
  #limInfpon: límite inferior de la regresion ponderada
  #limSuppon: límite superior de la regresion ponderada 
  #distribucion: distribucion que se requiere para el GLM
  #funcion_liga: funcion liga que se requiere para el GLM
  #numPesos: Parametro que nos dice cuantos direntes pesos tendremos que considerar a la hora de hacer regresion ponderada
  
  
  seq_values <- seq(liminf, limsup, by = finura)  #Creando las recuencias para la malla y posteriormente elevar la variable 
  df <- data.frame(matrix(ncol = 0, nrow = length(seq_values))) # Se creo el df, para poder poner las variables


  for (i in 1:n) {
    col_name <- paste("var_", i, sep = "")  # Crear nombre de columna
    df[[col_name]] <- seq_values  # Asignar los valores de la secuencia
  }
  
  df["Num_Ponderada"] <- c(1:numPesos,  rep(NA, times = length(seq_values) - numPesos))  #Definiendo las combinaciones de nuestro modelo de regresion ponderada
  
  if(!is.null(distribucion) ){ #Agregando los GLM
    df["GLM"] <- c(0, distribucion, rep(NA, times = length(seq_values) - length(distribucion)-1))
    df["liga"] <- c(funcion_liga, rep(NA, times = length(seq_values) - length(funcion_liga)))
  }
  
  if(des_Ponderada == 1){ #En caso de necesitar regresion donderada se agrega una columan con una secuencia de ponderada 
    #Maya de regresion ponderada donde se puede cntrolar los limites de la reg ponderda, pero su finura depede de la longitud del df
    df[["Ponderada"]] <- seq(limInfpon, limSuppon, length.out = length(seq_values)) 
    return(expand.grid(df))
  } else{
    expan <- expand.grid(df)
    expan[["Ponderada"]] <- rep(0, times = length(expan$var_1))
    return(expan)
  }

 
}


```


```{r Resultados_Malla}


limpieza_mallaa <- function(dfMalla){
  #Funcion para limpiar nuestra malla, ya que viene con varios NA y con filas repetidas
    clean <- dfMalla %>%
    drop_na() %>%  # Elimina filas con NA en cualquier columna
    distinct()     # Elimina filas duplicadas
    return( clean)
}
#Sin Na tengo 35,152

malla <- limpieza_mallaa(mallaAl(long_Modelo, limiteInfMalla, limSuperiorMalla, finura, 
                                 des_Ponderada = 1, limInfpon = 0, limSuppon = 2.5,  distribucion  = Distribuciones, funcion_liga= FunLigas, 2))








```



```{r Filtrando_modelos}
regresion <- malla %>% 
  filter(malla$GLM == "0" & malla$Ponderada == 0) %>% #Aplicamos el filtro para solo seleccionar las que seran para la regresion normal
  select(var_1, var_2)%>%  # Elimina filas con NA en cualquier columna
    distinct() 


#regresion

num_regresion <- length(regresion$var_1)

#Veamos el numero de regresiones normales
#num_regresion



regresion_Ponderada <- malla %>%
  filter( malla$Ponderada !=0) %>% #Aplicamos el filtro para solo seleccionar las que seran para la regresion normal
  select(var_1, var_2, Num_Ponderada, Ponderada)%>%  # Elimina filas con NA en cualquier columna
    distinct() 


num_regresion_Ponderada <- length(regresion_Ponderada$var_1)

#num_regresion_Ponderada


modelos_GLM  <- malla %>%
  filter(malla$GLM != "0") %>% #Aplicamos el filtro para solo seleccionar las que seran para la regresion normal
  select(var_1, var_2, GLM, liga)%>%  # Elimina filas con NA en cualquier columna
    distinct() 


num_modelos_GLM <- length(modelos_GLM$var_1)



```




```{r Total_Modelos}

total <- num_modelos_GLM + num_regresion_Ponderada + num_regresion


```


## Explicacion de  Algoritmo 

En el algoritmo empleado,  definimos una funcion que hacia una **Malla** (con todos los valores y  combinaciones posibles), para  **var_1 ** y  **var_2 **, se creeo a partir de una secuancia de [0,5] con 0.3 de incremento, luego se hizo la columna  **Num_Ponderada **, en ella se difinia que variable iba a tomar el peso en nuestra regresion poderada, donde el peso se definia en la columna **Ponderada**, para los modelos generales lineales, se emplearon las columnas  **Num_Ponderada ** y  **GLM **.



```{r}
head(malla) %>%
  kable(format = "html", caption = "Primeros datos") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                full_width = FALSE, position = "center")
```

Ejemplo de como se veia el data frame **malla**, con los 10 primero elementos, este data frame contenia: `R length(malla$var_1) ` combinaciones. 


Posteriormente se realizo un filtrado a nuestra **malla**, pasar saber que tipo de modelo ibamos a evaluar con cada fila, este proceso ayudo a reducir el numero de modelo a evaluar, ya que quitaba elemento repetido de nuestra **malla**, los criterios para esta eleccion, fueron:

- Si las columnas **GLM** y **Ponderada** eran iguales a 0, entonces se aplicaba in modelo de regresion multiple. Donde E[bpsystol] =  bmi^**var_1** +  age^**var_2** + sex

- Si la columna **Ponderada** era igual a 0, entonces aplicabamos regresion ponderada, donde con **Num:ponderada** elegiamos a que variable **bmi** o **age**, le ibamos a asignar el peso

+ Si **Num_Ponderada** era igual a 1, entonces  E[bpsystol] =  bmi^**var_1** +  age^**var_2** + sex, weights = 1/ bmi ^ **Ponderada**, en caso contrario E[bpsystol] =  bmi^**var_1** +  age^**var_2** + sex, weights = 1/ age ^ **Ponderada**


- Como ultimo caso, si **GLM** era distinto de 0, aplicabamos un modelo GLM, donde liga( E[bpsystol] ) =  bmi^**var_1** +  age^**var_2** + sex


Con todo esto, evaluamos un total de `R total` modelos de los cuales,  evaluamos  `R  num_regresion ` modelos de regresion multiple,    `R num_regresion_Ponderada` modelos de regresion ponderada,    `R  num_modelos_GLM ` modelos GLM.    


```{r Procesamiento_datos}

# Evaluando los modelos de regresion multivariada
evaluando_regresion <- apply(regresion, 1 ,function(df){
    AIC(lm(bpsystol ~  I(bmi^df[1]) + I(age^df[2]) + sex , data = data))
})


AIC_regresion <- data.frame(regresion, AIC = unlist(evaluando_regresion))


#Evaluando los modelos de regrecion multivarada ponderada
evaluando_regresion_Ponderada <- apply(regresion_Ponderada, 1, function(df){
   if(df[3] == 1){
        AIC(lm(bpsystol ~  I(bmi^df[1]) + I(age^df[2]) + sex , weights = 1 / I(bmi^df[4]), data = data)) #Pondera en base a BMI
      } else{
        AIC(lm(bpsystol ~  I(bmi^df[1]) + I(age^df[2]) + sex , weights = 1 / I(age^df[4]), data = data)) #Pondera en base a age
      }
})

AIC_regresion_Ponderada <- data.frame(regresion_Ponderada, AIC = unlist(evaluando_regresion_Ponderada))



#Evaluando los modelos GLMs
evaluando_modelos_GLM <- apply(modelos_GLM, 1, function(df){
   fam_selec <- get(as.character(df[3])) #Seleccionamios la funcion que viene en la palabra  
   AIC(glm(bpsystol ~  I(bmi^as.numeric(df[1])) + I(age^as.numeric(df[2])) + sex , data = data, family = fam_selec(link =df[4])))
  
})

AIC_modelos_GLM <- data.frame(modelos_GLM, AIC= unlist(evaluando_modelos_GLM))

```





```{r Uniendo_DF}


# Uniendo los dataframes como una pila
AIC_Models <- bind_rows(AIC_regresion, AIC_regresion_Ponderada, AIC_modelos_GLM )


```






```{r Seleccion_Modelos}
n <- 10 # Numero de modelos que queremos

# Ordenar los valores de AIC y seleccionar los n más pequeños
indices_minimos <- order(AIC_Models$AIC)[1:n]

# Crear un data frame con los n valores mínimos de AIC y sus respectivos parámetros
df_minimos <- AIC_Models[indices_minimos, ]


head(df_minimos) %>%
  kable(format = "html", caption = "Top 10 mejores modelos") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                full_width = FALSE, position = "center")

```



```{r}
#Comprobacion Aic

 AIC(lm(bpsystol ~  I(bmi^1.5) + I(age^4) + sex , weights = 1 / I(age^0.6666667), data = data)) #Pondera en base a BMI


```






```{r}

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```











