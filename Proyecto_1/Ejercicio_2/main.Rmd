---
author: "Fernando Alvarado"
date: "2025-03-12"
output: html_document
---


```{r setup, include=FALSE}
#Empezamos limpiando nuestro ambiente
rm(list = ls(all.names = TRUE))


# Configuración global de los bloques de código (chunk's)
knitr::opts_chunk$set(
	echo = FALSE,
	fig.align = "center",
	fig.dim = c(5.0, 4.0),
	fig.pos = "H",
#Agregamos configuraciones para evitar mensajes de advertencias y de errores en el archivo
	message = FALSE,
	warning = FALSE,
	error = F
)



library(dplyr)      # Para el manejo de datos
library(tidyr)

library(ggplot2)    # Para realizar gráficas
library(kableExtra) # Para un mejor manejo de tablas
library(purrr)      # Para la función map y map2


# Para purebas de hipotesis





#Extrayendo nuestra data
setwd("C:/Users/ferna/Documents/Seminario_Estadistica/Proyecto_1/Ejercicio_1")

data <- read.csv("./Data/Preg1A.csv")




```


Reporte donde seleccionaremos el mejor algoritmo de Regresion o MLG


```{r}
head(data)
```


#------------------------------------------------------------------------------------------------------------------------------------------
#Algoritmo de selección de modelos en base a su AIC y BIC
#------------------------------------------------------------------------------------------------------------------------------------------



```{r}
#------------------------------------------------------------------------------------------------------------------------------------------
#Hiperparámetros de nuestro algoritmo 



#Primeros parametros de nuestro algoritmo de la malla 

long_Modelo <- 2 #Longitud que tengra nuestro modelo 
limiteInfMalla <- -1 #Lo que la malla debe de empezar a checar
limSuperiorMalla <- 5 #Limite superior malla
finura <- .5 #Para empezar a hacer pruebas 


#Primeros GLMS

(Distribuciones=c("gaussian", "Gamma", "inverse.gaussian"))
(FunLigas=c("identity", "log", "inverse", "1/mu^2"))


```


```{r Algoritmo_Malla}
#------------------------------------------------------------------------------------------------------------------------------------------
#Algoritmo malla (Aqui hare la malla para poder elevar a las variables a la potencia que se requiera)



malla <- function(n, liminf, limsup, finura, des_Ponderada = 0 , limInfpon = 0, limSuppon = 2, distribucion  = c(), funcion_liga= c(), numPesos){
  #Parametros
  #n: número de parametros que tiene nuestro modelo 
  #liminf: límite inferior de la malla, para las variables x
  #limsup: límite superior de la malla, para las variables x
  #finura: finura de la malla que deseamos
  #des_Ponderada: si se requiere usar regresion ponderada
  #limInfpon: límite inferior de la regresion ponderada
  #limSuppon: límite superior de la regresion ponderada 
  #distribucion: distribucion que se requiere para el GLM
  #funcion_liga: funcion liga que se requiere para el GLM
  #numPesos: Parametro que nos dice cuantos direntes pesos tendremos que considerar a la hora de hacer regresion ponderada
  
  
  seq_values <- seq(liminf, limsup, by = finura)  #Creando las recuencias para la malla y posteriormente elevar la variable 
  df <- data.frame(matrix(ncol = 0, nrow = length(seq_values))) # Se creo el df, para poder poner las variables


  for (i in 1:n) {
    col_name <- paste("var_", i, sep = "")  # Crear nombre de columna
    df[[col_name]] <- seq_values  # Asignar los valores de la secuencia
  }
  
  df["Num_Ponderada"] <- c(1:numPesos,  rep(NA, times = length(seq_values) - numPesos))  #Definiendo las combinaciones de nuestro modelo de regresion ponderada
  
  if(!is.null(distribucion) ){ #Agregando los GLM
    df["GLM"] <- c(0, distribucion, rep(NA, times = length(seq_values) - length(distribucion)-1))
    df["liga"] <- c(funcion_liga, rep(NA, times = length(seq_values) - length(funcion_liga)))
  }
  
  if(des_Ponderada == 1){ #En caso de necesitar regresion donderada se agrega una columan con una secuencia de ponderada 
    #Maya de regresion ponderada donde se puede cntrolar los limites de la reg ponderda, pero su finura depede de la longitud del df
    df[["Ponderada_1"]] <- seq(limInfpon, limSuppon, length.out = length(seq_values)) 
    return(expand.grid(df))
  } else{
    expan <- expand.grid(df)
    expan[["Ponderada_1"]] <- rep(0, times = length(expan$var_1))
    return(expan)
  }

 
}


```


```{r Resultados_Malla}


limpieza_mallaa <- function(dfMalla){
  #Funcion para limpiar nuestra malla, ya que viene con varios NA y con filas repetidas
    clean <- dfMalla %>%
    drop_na() %>%  # Elimina filas con NA en cualquier columna
    distinct()     # Elimina filas duplicadas
    return( clean)
}
#Sin Na tengo 35,152

malla <- limpieza_mallaa(malla(long_Modelo, limiteInfMalla, limSuperiorMalla, finura, 
                                 des_Ponderada = 1, limInfpon = 0, limSuppon = 2,  distribucion  = Distribuciones, funcion_liga= FunLigas, 2))


malla

print(length(malla$var_1))
```

```{r}
typeof(malla$Ponderada_1)

typeof(malla$liga)


```





```{r ProcesacmientO_modelos}
#Aplicando las combinaciones de la malla a nuestro modelo

AIC_Models <- apply(malla, 1, function(df){
    num <- as.numeric(c(df[1],df[2],df[3],df[6])) #Pasando a numero los, string que vienen en la malla
    str<- as.character(c(df[4], df[5])) #Pasando a caracter nuestro df, para no tener problemas de tipo en R
    
    
    if(str[1] == "0" && num[4] == 0 ){ #Condicionla para checar que no consideramos ni regresion ponderada ni GLM
        AIC(lm(bpsystol ~  I(bmi^num[1]) + I(age^num[2]) + sex , data = data))
    }else if(str[1] == "0"){
      if(num[3] == 1){
        AIC(lm(bpsystol ~  I(bmi^num[1]) + I(age^num[2]) + sex , weights = 1 / I(bmi^num[4]), data = data)) #Pondera en base a BMI
      } else{
        AIC(lm(bpsystol ~  I(bmi^num[1]) + I(age^num[2]) + sex , weights = 1 / I(age^num[4]), data = data)) #Pondera en base a age
      }
    }else{ #Ahora si aplicamos los modelos GLMs
       fam_selec <- get(str[1]) #Seleccionamios la funcion que viene en la palabra  
       AIC(lm(bpsystol ~  I(bmi^num[1]) + I(age^num[2]) + sex , data = data, family = fam_selec(link = str[2])))
    }
  
})

#df[1]    var 2
#df[2]    var 1
#df[3]    Numero de modelo ponderados
#df[6]    Poderada



```


```{r Resultados}
Resultado_Modelos <- data.frame(malla, AIC = unlist(AIC_Models))
Resultado_Modelos

```



```{r Seleccion_Modelos}
n <- 30 # Cambia según lo que necesites

# Ordenar los valores de AIC y seleccionar los n más pequeños
indices_minimos <- order(Resultado_Modelos$AIC)[1:n]

# Crear un data frame con los n valores mínimos de AIC y sus respectivos parámetros
df_minimos <- Resultado_Modelos[indices_minimos, ]


df_minimos

```



```{r}
#Comprobacion Aic

 AIC(lm(bpsystol ~  I(bmi^1.5) + I(age^4) + sex , weights = 1 / I(age^0.6666667), data = data)) #Pondera en base a BMI


```




# Preubas 


```{r}
data(mtcars)

# Ajustar el modelo con interacción
modelo_interaccion <- lm(mpg ~ wt * hp, data = mtcars)

# Mostrar el resumen del modelo
summary(modelo_interaccion)


names(modelo_interaccion$coefficients)[2]   #Obteniendo el nombre del primer coeficiente 



 modelo <- function(modelado, vector_modela, data){
   mod <- lm(modelado )
   
 }
```




```{r}
char_vector <- c("10", "20", "30")
num_vector <- as.numeric(char_vector)
print(num_vector)



num_vector[1] * num_vector[1] 

```



```{r}

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```











